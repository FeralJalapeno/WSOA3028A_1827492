<!DOCTYPE html><html>
    <head>
        <link rel="stylesheet" href="D:\Interactive Media\Interactive_Media\Git_Hub_Stuff\WSOA3028A_1827492\poststyle.css">
    </head>
    <body>
        <button onclick="goBack()">Go Back</button>

        <script>
        function goBack() {
          window.history.back();
        }
        
        </script>
        <h1>The tech industry doesn’t have a plan for dealing with bias in facial recognition</h1>

        <p>Facial recognition is rapidly becoming a big part of our modern lives. Most smart phones are moving towards facial recognition technologies. The industries fail to provide enough effort to combat the underlying structural problems, especially the concern of bias. An <a href= https://www.theverge.com/2018/7/26/17616290/facial-recognition-ai-bias-benchmark-test> article by James Vincent discusses this issue</a> </p>
<p>Researchers from the MIT Media Lab found that the facial recognition algorithms designed by Microsoft, IBM and Face ++ have error rates up to 35% higher when detecting the gender of dark-skinned women. Vincent states that this bias in facial recognition “threatens to reinforce the prejudices of society; disproportionately affecting women and minorities, potentially locking them out of the world’s digital infrastructure, or inflicting life-changing judgements on them.” I heavily agree with him. These algorithms do no favours in helping us as a society move away from the prejudices that darker skinned women face.</p>
<p>The worst part is that barely anything is being done to fix this issue. Many companies are aware of these biases but refuse to share their detailed findings or progress on trying to combat it. As a darker skinned woman who has been faced with racism and colourism, I find this heavily disappointing. If I was using a company’s facial recognition algorithm, I would genuinely like to know if it worked poorly with my skin tone and gender. </p>
<p>Unfortunately, data bases are often biased. Most of it is made using white people as models for the algorithm since its usually all the creators have access to. The only way to reduce an algorithms bias is to feed is diverse data. The lack of diversity in these training datasets are the core to the problem. Simple things, like making sure the subjects skin tone is properly exposed, matter. They make a difference since the algorithm is receiving more accurate data.</p>

    </body>
    </html>