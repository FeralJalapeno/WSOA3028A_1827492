<!DOCTYPE html><html>
    <head>
        <link rel="stylesheet" href="D:\Interactive Media\Interactive_Media\Git_Hub_Stuff\WSOA3028A_1827492\poststyle.css">
    </head>
    <body>
        <button onclick="goBack()">Go Back</button>



        <script>
        function goBack() {
          window.history.back();
        }
        </script>
<h1>THESE FACIAL RECOGNITION ALGORITHYMS ARE HARMFUL</h1>
<p>Looking at the previous two blog posts on these facial recognition technologies, we can confirm that they are not reliable or successful enough to be implemented into something serious like identifying criminals- even before any crimes have been committed. But when it comes to people of colour, this technology can potentially cause severe harm and injustice to them</p>
<p>As a woman of colour, I find it very important that many people are aware of the facial recognition technologies and what they are being used for. In a YouTube video - <a href="https://www.youtube.com/watch?v=mxektG_wU4w">Alexandria Ocasio-Cortez Exposes Dangers of Facial Recognition</a>, the dangers of these technologies are discussed and blatantly brought to light. With no hesitation or denial, it is said that many companies, including Amazon scan their users faces and sell/use their biometric data without their consent. This data is sought after many companies that wish to use it to create crime identification algorithms. </a></p>
<p>In the video, it is asked if these systems are effective on women and people of colour. Of course, they are not effective to either of these groups. In fact, these systems don’t even cater to people of different gender expressions. But why is this? Why do these algorithms fail these three large groups of people? The answer is simple. It’s because these systems are created by white males. To make it even more evident, these system are only highly effective with white males. Not surprising at all if you ask me.</p>
<p>The primary engineers and creators of these algorithms are white males. Its simply ONE demographic creating a system that is only effective towards that one demographic-themselves. These systems are trying to be sold to an entire country, such as America, to be used for criminal identification. This is extremely problematic as it currently is being implemented and intensifies the inequalities in the criminal justice system. If more systems like this are implemented, these inequalities would only peak. I find it sickening how biometric data that it taken, used and distributed without consent is being used for such.</p>
<p> The video also shares an example of how these systems currently disadvantage people of colour and contribute to the biases of the criminal justice system. A black male, Mr Bah, had been picked up by Apples facial scanners and had been flagged as a criminal, despite there being no criminal activity. He had been misidentified as a thief and had been wrongly arrested, multiple times. This is why these algorithms are so problematic. They keep showing how inaccurate they can be based off of the people who create them and the information it is fed. These systems only seem to intensify the racial biases we are meant to be moving away from in our society. Clearly, not enough is being done to address this.</p>



        </body>
</html>