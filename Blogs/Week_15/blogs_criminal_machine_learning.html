<!DOCTYPE html><html>
    <head>
        
    </head>
    <body>
        <button onclick="goBack()">Go Back</button>



        <script>
        function goBack() {
          window.history.back();
        }
        </script>

        <h1>CRIMINAL MACHINE LEARNING</h1>
        <hr>
        <p>Xialin Wu and Xi Zhang are the authors of Automated Inference on Criminality using Face Images.
            In this article they explore the methods of machine learning 
            and how it can detect features of a human face that are associated
            with Criminality. They claim that they have developed algorithms
            that can analyse a headshot that has the ability to differentiate between criminals and non-criminals with high accuracy.

            Of course, there are ethical implications that come with this.
        </p>
        <p> Let's say it was possible to identify a criminal based of the structure of their face,
            we would face an incredible ethical challenge.
            How do you justify calling someone a criminal before they've commited any crime? Saying they " look like a criminal"
            isn't good enough. It can actually end us leading to an immense state of bias and prejudice.

        </p>
        <p> In the 19th century, Cesare Lombroso studied the anatomy of hundreds of criminals.
            The point was to develop some sort of scientific theory on criminal behavior.
            He did claim that some facial features made a criminal - but obviously this was proven to be false.
            In fact, many of his claims were just excuses to be racist while hiding that racism with scientific terms. 
            Not surprising, since there is a vast history of using 'science' to opress people.

        </p>
        <p>Wu and Zhang aimed to reveal if machine learning could pick up on subtle things no human could.
            Turns out, their programs can distinguish criminals with a 90% accuracy (most of the time).
            They argue that these algorithms are free from biases and prejudices.
            Unlike people, a computer has no emotion, race or religion from which these biases can emerge.
            But, a machine can only be as un-biased as the training data it is provided with.

        </p>
        <p>Wu and Zhang used about 1800 photos of Chinese men with no distinguishing
            facial hair, scars and tattoos. Just over 700 of these phtos were of actual criminals- provided
            by their police departments. They note that these photos are of convicted criminals.
            The issue is that the pictures used of the non-criminals were taken from websites and profiles.
            Many of these pictures are chosen by the subject of picture, most likely to convey a positive 
            impression. In contrast, the images of criminals are mug-shots- something where a positive impression
            is not the intention. These photos are not similar to the nature of the non-criminal photos.
        </p>
        <p>The other issue is that the pictures used are of convicted criminals.This results in the algorithm responding to facial features that would make someonelikely to be convicted by a jury, instead of facial features
            directly correlated with commiting crimes.
            Unfortunately, it was found that unattractive individuals are more likely to be found guilty 
            during trials and the more attractive individuals are not. See how these two issues link? 
            Eventually the algorithms would simply consider everyone who is considered unattractive according to societal norms as a criminal.
            
        </p>
    </body>
</html>